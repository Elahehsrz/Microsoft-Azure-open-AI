{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and setting up Azure Open AI and Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timezone\n",
    "from random import randint\n",
    "import openai\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.chains import LLMChain\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"ENDPOINT\", default=None)\n",
    "key = os.getenv(\"KEY\", default=None)\n",
    "deployment_name = os.getenv(\"DEPLOYMENT_NAME\", default=None)\n",
    "model_preview = \"2023-06-01-preview\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=deployment_name,\n",
    "    api_key=key,  \n",
    "    api_version=model_preview,\n",
    "    azure_endpoint = endpoint\n",
    "\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json_data = \"data/feedbacks.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_random_rows(df, n):\n",
    "    # Take n random rows from DataFrame\n",
    "    random_rows = df.sample(n)\n",
    "    return random_rows\n",
    "\n",
    "\n",
    "def create_dataframe_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Load JSON data\n",
    "    \n",
    "    # Extract feedbacks\n",
    "    feedbacks = data.get('feedbacks', {})\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    ids = []\n",
    "    feedback_texts = []\n",
    "\n",
    "    # Iterate over feedbacks and categories simultaneously\n",
    "    for i, (key, feedback) in enumerate(feedbacks.items()):\n",
    "        # Extract feedback id and text\n",
    "        feedback_id = feedback.get('id')\n",
    "        feedback_text = feedback.get('feedback')\n",
    "        \n",
    "        # Append data to lists\n",
    "        ids.append(feedback_id)\n",
    "        feedback_texts.append(feedback_text)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'feedback': feedback_texts\n",
    "    })\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = create_dataframe_from_json(path_to_json_data)\n",
    "df = get_random_rows(df, 150)\n",
    "print(\"df\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_from_json_file(json_file_path):\n",
    "    with open(json_file_path) as f:\n",
    "        json_data = f.read()\n",
    "\n",
    "    json_dict = json.loads(json_data)\n",
    "\n",
    "    categories = json_dict['categories']\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_items_in_a_list(my_list):\n",
    "    new_list = []\n",
    "    for item in my_list:\n",
    "        sub_items = item.split(',')\n",
    "        for sub_item in sub_items:\n",
    "            if sub_item not in new_list:\n",
    "                new_list.append(sub_item)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categories from the data:\n",
    "\n",
    "# Example usage\n",
    "categories = extract_categories_from_json_file(path_to_json_data)\n",
    "print(categories)\n",
    "print(len(categories))\n",
    "\n",
    "# Get the list of unique items\n",
    "unique_categories = unique_items_in_a_list(categories)\n",
    "print(unique_categories)\n",
    "print(len(unique_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 0.0038220882415771484 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "unique_categories = unique_items_in_a_list(categories)\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "print(\"Processing time:\", processing_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classification_prompt = \"\"\"\n",
    "Act as a highly intelligent feedback analyser and classify the given feedbacks text into one of the following sentiments only 1. positive 2.negative 3.neutral 4. other\n",
    "Do not code. Return only one word answer with only the sentiment that the given feedback text belongs to\n",
    "feedback: {feedback}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_classification_prompt() -> PromptTemplate:\n",
    "    \"\"\"\n",
    "    Create a prompt template for LLM\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PromptTemplate\n",
    "        Prompt template in the LangChain format\n",
    "    \"\"\"\n",
    "\n",
    "    # build the template\n",
    "    llm_prompt = PromptTemplate(\n",
    "        input_variables=[\"feedback\"], template=sentiment_classification_prompt\n",
    "    )\n",
    "    return llm_prompt\n",
    "\n",
    "llm_prompt = create_classification_prompt()\n",
    "print(llm_prompt )\n",
    "llm_chain = LLMChain(llm=llm, prompt=llm_prompt, output_key=\"response\", verbose=False, memory=None)\n",
    "print(llm_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiment  = llm_chain.run( df.iloc[132]['feedback'])\n",
    "predicted_sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_sentiment_column(df):\n",
    "    # Add empty column 'sentiment'\n",
    "    df = df.assign(sentiment='')\n",
    "    return df\n",
    "\n",
    "# make the prediction and add it back to the datarame\n",
    "def add_column_predicted_labels(df, llm_chain):\n",
    "    #df = df.dropna()\n",
    "    for row in df.itertuples():\n",
    "        df.at[row.Index, \"sentiment\"] = llm_chain.run(row.feedback).lower() \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ThreadPoolExecutor instance with 4 worker threads\n",
    "start_time = time.time()\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "# define a function to make the LLM request\n",
    "def make_llm_request_lower(llm_chain, feedback):\n",
    "    return llm_chain.run(feedback).lower()\n",
    "\n",
    "# iterate over your dataframe and submit llm requests to the executor\n",
    "futures = []\n",
    "for row in df.itertuples():\n",
    "    future = executor.submit(make_llm_request_lower, llm_chain, row.feedback)\n",
    "    futures.append(future)\n",
    "\n",
    "# wait for all requests to complete and collect the results\n",
    "results = []\n",
    "for future in concurrent.futures.as_completed(futures):\n",
    "    result = future.result()\n",
    "    results.append(result)\n",
    "\n",
    "# add the predicted labels to the dataframe\n",
    "df[\"sentiment\"] = results\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "print(\"Processing time:\", processing_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_classification_prompt= \"\"\"\n",
    "Act as a highly intelligent feedback classifier and classify the given feedback text into one or more than of the following categories:\n",
    "<feedback_categories>\n",
    "{categories}\n",
    "</feedback_categories>.\n",
    "Do not code. Return only the category names that the given news text belongs to.\n",
    "<feedback>\n",
    "{feedback}\n",
    "</feedback>.\n",
    "Categories:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_category_classification_prompt(categories) -> PromptTemplate:\n",
    "    \"\"\"\n",
    "    Create a prompt template for LLM\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PromptTemplate\n",
    "        Prompt template in the LangChain format\n",
    "    \"\"\"\n",
    "\n",
    "    # build the template\n",
    "    llm_prompt = PromptTemplate(\n",
    "        input_variables=[\"feedback\", \"categories\"], template=category_classification_prompt\n",
    "    )\n",
    "    llm_prompt = llm_prompt.partial(categories=categories)\n",
    "    return llm_prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_prompt2 = create_category_classification_prompt(unique_categories)\n",
    "print(llm_prompt2 )\n",
    "llm_chain2 = LLMChain(llm=llm, prompt=llm_prompt2, output_key=\"response\", verbose=False, memory=None)\n",
    "print(llm_chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[132]['feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category  = llm_chain2.run( df.iloc[132]['feedback'])\n",
    "predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ThreadPoolExecutor instance with 4 worker threads\n",
    "start_time = time.time()\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "def make_llm_request(llm_chain, feedback):\n",
    "    return llm_chain.run(feedback)\n",
    "\n",
    "# iterate over your dataframe and submit llm requests to the executor\n",
    "futures = []\n",
    "for row in df.itertuples():\n",
    "    future = executor.submit(make_llm_request, llm_chain2, row.feedback)\n",
    "    futures.append(future)\n",
    "\n",
    "# wait for all requests to complete and collect the results\n",
    "results = []\n",
    "for future in concurrent.futures.as_completed(futures):\n",
    "    result = future.result()\n",
    "    results.append(result)\n",
    "\n",
    "# add the predicted labels to the dataframe\n",
    "df[\"category\"] = results\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "print(\"Processing time:\", processing_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sentiment= df['sentiment'].unique()\n",
    "\n",
    "print(unique_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/my_dataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
